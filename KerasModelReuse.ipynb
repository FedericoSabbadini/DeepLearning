{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FedericoSabbadini/DeepLearning/blob/main/KerasModelReuse.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "KdAi0sGq680i"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFNvCCSd680i"
      },
      "source": [
        "This project requires Python 3.7 or above:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "JAmaeIFg680j"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "assert sys.version_info >= (3, 7)\n",
        "\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzJaazlL680m"
      },
      "source": [
        "And TensorFlow ≥ 2.8:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "jLJZmpFf680n"
      },
      "outputs": [],
      "source": [
        "from packaging import version\n",
        "import tensorflow as tf\n",
        "\n",
        "assert version.parse(tf.__version__) >= version.parse(\"2.8.0\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YqEDo4y680o"
      },
      "source": [
        "As we did in previous chapters, let's define the default font sizes to make the figures prettier:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "O8TCzYLQ680o"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rc('font', size=14)\n",
        "plt.rc('axes', labelsize=14, titlesize=14)\n",
        "plt.rc('legend', fontsize=14)\n",
        "plt.rc('xtick', labelsize=10)\n",
        "plt.rc('ytick', labelsize=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MArCeZd680p"
      },
      "source": [
        "And let's create the `images/deep` folder (if it doesn't already exist), and define the `save_fig()` function which is used through this notebook to save the figures in high-res for the book:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "GxyA8qMJ680p"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "IMAGES_PATH = Path() / \"images\" / \"deep\"\n",
        "IMAGES_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = IMAGES_PATH / f\"{fig_id}.{fig_extension}\"\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
        "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
      ],
      "metadata": {
        "id": "3Lgo_VNGaTDT"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "FW4ATSKY680z"
      },
      "outputs": [],
      "source": [
        "fashion_mnist = tf.keras.datasets.fashion_mnist.load_data()\n",
        "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist\n",
        "X_train, y_train = X_train_full[:-5000], y_train_full[:-5000]\n",
        "X_valid, y_valid = X_train_full[-5000:], y_train_full[-5000:]\n",
        "X_train, X_valid, X_test = X_train / 255, X_valid / 255, X_test / 255"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape\n",
        "# X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29zQ_joooRKz",
        "outputId": "84e690de-0ac5-4bb2-9748-7dfe220fdeea"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(55000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PJ6XCcs681F"
      },
      "source": [
        "# Reusing Pretrained Layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjTdvvhY681F"
      },
      "source": [
        "### Reusing a Keras model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AynifTS681F"
      },
      "source": [
        "Let's split the fashion MNIST training set in two:\n",
        "* `X_train_A`: all images of all items except for T-shirts/tops and pullovers (classes 0 and 2).\n",
        "* `X_train_B`: a much smaller training set of just the first 200 images of T-shirts/tops and pullovers.\n",
        "\n",
        "The validation set and the test set are also split this way, but without restricting the number of images.\n",
        "\n",
        "We will train a model on set A (classification task with 8 classes), and try to reuse it to tackle set B (binary classification). We hope to transfer a little bit of knowledge from task A to task B, since classes in set A (trousers, dresses, coats, sandals, shirts, sneakers, bags, and ankle boots) are somewhat similar to classes in set B (T-shirts/tops and pullovers). However, since we are using `Dense` layers, only patterns that occur at the same location can be reused (in contrast, convolutional layers will transfer much better, since learned patterns can be detected anywhere on the image, as we will see in the chapter 14)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Model A"
      ],
      "metadata": {
        "id": "kxw4oRsXZCp6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "v3oBTAUK681F"
      },
      "outputs": [],
      "source": [
        "# extra code – split Fashion MNIST into tasks A and B, then train and save\n",
        "#              model A to \"my_model_A\".\n",
        "\n",
        "pos_class_id = class_names.index(\"Pullover\")\n",
        "neg_class_id = class_names.index(\"T-shirt/top\")\n",
        "\n",
        "def split_dataset(X, y):\n",
        "    y_for_B = (y == pos_class_id) | (y == neg_class_id)\n",
        "    y_A = y[~y_for_B]\n",
        "    y_B = (y[y_for_B] == pos_class_id).astype(np.float32)\n",
        "    old_class_ids = list(set(range(10)) - set([neg_class_id, pos_class_id]))\n",
        "    for old_class_id, new_class_id in zip(old_class_ids, range(8)):\n",
        "        y_A[y_A == old_class_id] = new_class_id  # reorder class ids for A\n",
        "    return ((X[~y_for_B], y_A), (X[y_for_B], y_B))\n",
        "\n",
        "(X_train_A, y_train_A), (X_train_B, y_train_B) = split_dataset(X_train, y_train)\n",
        "(X_valid_A, y_valid_A), (X_valid_B, y_valid_B) = split_dataset(X_valid, y_valid)\n",
        "(X_test_A, y_test_A), (X_test_B, y_test_B) = split_dataset(X_test, y_test)\n",
        "X_train_B = X_train_B[:200]\n",
        "y_train_B = y_train_B[:200]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_A.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHVSPAzFpaYZ",
        "outputId": "a8171aa5-055b-4f2b-e389-3c831a516580"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(44011, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(43)\n",
        "\n",
        "model_A = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\",\n",
        "                          kernel_initializer=\"he_normal\"),\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\",\n",
        "                          kernel_initializer=\"he_normal\"),\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\",\n",
        "                          kernel_initializer=\"he_normal\"),\n",
        "    tf.keras.layers.Dense(8, activation=\"softmax\") # 8 classi finali, serve distribuzione di probabilità con softmax\n",
        "])\n",
        "\n",
        "model_A.compile(loss=\"sparse_categorical_crossentropy\", # con sparse converte gli 8 in un vettore\n",
        "                optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),\n",
        "                metrics=[\"accuracy\"]) # meglio altra metrica se non bilanciate, qua lo sono\n",
        "history = model_A.fit(X_train_A, y_train_A, epochs=20,\n",
        "                      validation_data=(X_valid_A, y_valid_A))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjqQsqMypLMd",
        "outputId": "0538e101-fa9f-4193-e1c4-f2e241bc7799"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5158 - loss: 1.5686 - val_accuracy: 0.7471 - val_loss: 0.7286\n",
            "Epoch 2/20\n",
            "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7578 - loss: 0.6768 - val_accuracy: 0.8135 - val_loss: 0.5526\n",
            "Epoch 3/20\n",
            "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8209 - loss: 0.5360 - val_accuracy: 0.8483 - val_loss: 0.4732\n",
            "Epoch 4/20\n",
            "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8512 - loss: 0.4628 - val_accuracy: 0.8589 - val_loss: 0.4236\n",
            "Epoch 5/20\n",
            "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8654 - loss: 0.4156 - val_accuracy: 0.8701 - val_loss: 0.3909\n",
            "Epoch 6/20\n",
            "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8736 - loss: 0.3835 - val_accuracy: 0.8764 - val_loss: 0.3680\n",
            "Epoch 7/20\n",
            "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8797 - loss: 0.3604 - val_accuracy: 0.8837 - val_loss: 0.3509\n",
            "Epoch 8/20\n",
            "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8841 - loss: 0.3428 - val_accuracy: 0.8872 - val_loss: 0.3374\n",
            "Epoch 9/20\n",
            "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8878 - loss: 0.3289 - val_accuracy: 0.8897 - val_loss: 0.3266\n",
            "Epoch 10/20\n",
            "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8907 - loss: 0.3175 - val_accuracy: 0.8910 - val_loss: 0.3177\n",
            "Epoch 11/20\n",
            "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8936 - loss: 0.3080 - val_accuracy: 0.8927 - val_loss: 0.3102\n",
            "Epoch 12/20\n",
            "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8961 - loss: 0.2997 - val_accuracy: 0.8950 - val_loss: 0.3036\n",
            "Epoch 13/20\n",
            "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8987 - loss: 0.2925 - val_accuracy: 0.8952 - val_loss: 0.2980\n",
            "Epoch 14/20\n",
            "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9006 - loss: 0.2860 - val_accuracy: 0.8975 - val_loss: 0.2930\n",
            "Epoch 15/20\n",
            "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9022 - loss: 0.2803 - val_accuracy: 0.8995 - val_loss: 0.2886\n",
            "Epoch 16/20\n",
            "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9039 - loss: 0.2750 - val_accuracy: 0.9012 - val_loss: 0.2847\n",
            "Epoch 17/20\n",
            "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9051 - loss: 0.2701 - val_accuracy: 0.9025 - val_loss: 0.2810\n",
            "Epoch 18/20\n",
            "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9076 - loss: 0.2656 - val_accuracy: 0.9035 - val_loss: 0.2777\n",
            "Epoch 19/20\n",
            "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9093 - loss: 0.2615 - val_accuracy: 0.9045 - val_loss: 0.2746\n",
            "Epoch 20/20\n",
            "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9106 - loss: 0.2577 - val_accuracy: 0.9067 - val_loss: 0.2718\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "( 1376 sono i batch (32 batch, default) eseguiti in sequenza. Aumentando i batch il numero di iterazioni per epoca diminuisce, ma richiede più tempo per processare più dati. )"
      ],
      "metadata": {
        "id": "aEjERr_Eq8QX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_A.evaluate(X_test_A, y_test_A)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9B9hcUnbQgc",
        "outputId": "b2fb7822-394e-451d-8650-15afe1cd9807"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8971 - loss: 0.2886\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2866709530353546, 0.8987500071525574]"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model B reaches 89.8% accuracy on its test set."
      ],
      "metadata": {
        "id": "nqK8Ks3kglg1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_A.save(\"my_model_A.keras\")"
      ],
      "metadata": {
        "id": "6gyNZyEIbtpU"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Model B"
      ],
      "metadata": {
        "id": "hiDMv8DvZI_m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "_mqjP0Xl681G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0841784d-e46a-4ef0-f2aa-c76300b99151"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 174ms/step - accuracy: 0.7103 - loss: 0.6362 - val_accuracy: 0.7290 - val_loss: 0.6337\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8239 - loss: 0.6076 - val_accuracy: 0.8012 - val_loss: 0.6089\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8718 - loss: 0.5831 - val_accuracy: 0.8497 - val_loss: 0.5879\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8907 - loss: 0.5620 - val_accuracy: 0.8724 - val_loss: 0.5688\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9116 - loss: 0.5431 - val_accuracy: 0.8912 - val_loss: 0.5520\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9165 - loss: 0.5258 - val_accuracy: 0.8961 - val_loss: 0.5365\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9360 - loss: 0.5096 - val_accuracy: 0.9021 - val_loss: 0.5222\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9379 - loss: 0.4942 - val_accuracy: 0.9090 - val_loss: 0.5090\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9487 - loss: 0.4797 - val_accuracy: 0.9120 - val_loss: 0.4969\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9636 - loss: 0.4663 - val_accuracy: 0.9149 - val_loss: 0.4857\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9636 - loss: 0.4539 - val_accuracy: 0.9159 - val_loss: 0.4752\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9636 - loss: 0.4421 - val_accuracy: 0.9189 - val_loss: 0.4653\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9662 - loss: 0.4308 - val_accuracy: 0.9199 - val_loss: 0.4559\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9662 - loss: 0.4200 - val_accuracy: 0.9209 - val_loss: 0.4469\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9681 - loss: 0.4096 - val_accuracy: 0.9268 - val_loss: 0.4383\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9681 - loss: 0.3996 - val_accuracy: 0.9308 - val_loss: 0.4299\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9681 - loss: 0.3899 - val_accuracy: 0.9327 - val_loss: 0.4218\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9681 - loss: 0.3806 - val_accuracy: 0.9337 - val_loss: 0.4140\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9681 - loss: 0.3716 - val_accuracy: 0.9357 - val_loss: 0.4065\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9681 - loss: 0.3631 - val_accuracy: 0.9367 - val_loss: 0.3992\n"
          ]
        }
      ],
      "source": [
        "# extra code – train and evaluate model B, without reusing model A\n",
        "\n",
        "tf.random.set_seed(43)\n",
        "model_B = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\",\n",
        "                          kernel_initializer=\"he_normal\"),\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\",\n",
        "                          kernel_initializer=\"he_normal\"),\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\",\n",
        "                          kernel_initializer=\"he_normal\"),\n",
        "    tf.keras.layers.Dense(1, activation=\"sigmoid\") # solo 1 uscita, no softmax\n",
        "])\n",
        "\n",
        "model_B.compile(loss=\"binary_crossentropy\", # ora abbiamo solo due classi\n",
        "                optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),\n",
        "                metrics=[\"accuracy\"])\n",
        "history = model_B.fit(X_train_B, y_train_B, epochs=20,\n",
        "                      validation_data=(X_valid_B, y_valid_B))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_B.evaluate(X_test_B, y_test_B)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eq1eTyDxb21E",
        "outputId": "e9d740e8-e9f9-40d1-9f95-6a32c1c2f771"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9347 - loss: 0.4056\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.40689003467559814, 0.9350000023841858]"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qdg4deaF681G"
      },
      "source": [
        "Model B reaches 89.7% accuracy on the test set. Now let's try reusing the pretrained model A."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reuse Model A"
      ],
      "metadata": {
        "id": "oG7XlOSjZNDS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "_HsIAVmw681H"
      },
      "outputs": [],
      "source": [
        "model_A = tf.keras.models.load_model(\"my_model_A.keras\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSdisWQM681H"
      },
      "source": [
        "Note that `model_B_on_A` and `model_A` actually share layers now, so when we train one, it will update both models. If we want to avoid that, we need to build `model_B_on_A` on top of a *clone* of `model_A`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "Ou8b6G2P681H"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(43)  # extra code – ensure reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "aLxJszNa681H"
      },
      "outputs": [],
      "source": [
        "model_A_clone = tf.keras.models.clone_model(model_A)\n",
        "model_A_clone.set_weights(model_A.get_weights())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "9QJG1c3i681I"
      },
      "outputs": [],
      "source": [
        "# extra code – creating model_B_on_A just like in the previous cell\n",
        "modelAB = tf.keras.Sequential(model_A.layers[:-1])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelAB.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))"
      ],
      "metadata": {
        "id": "gqAdu3xHx7UQ"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Not trainable layers\n",
        "for layer in modelAB.layers[:-1]:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "KNkGMrcdiOuP"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit\n",
        "modelAB.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "cdz0eVY5w2TR"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelAB.fit(X_train_B, y_train_B, epochs=5,\n",
        "            validation_data=(X_valid_B, y_valid_B))"
      ],
      "metadata": {
        "id": "wQNsr-gPw3OU",
        "outputId": "defa9633-5f36-4da1-a4da-aaae9d66d315",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 296ms/step - accuracy: 0.5698 - loss: 3.0383 - val_accuracy: 0.5153 - val_loss: 2.3501\n",
            "Epoch 2/5\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5698 - loss: 1.9763 - val_accuracy: 0.5153 - val_loss: 1.3027\n",
            "Epoch 3/5\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5717 - loss: 1.0755 - val_accuracy: 0.5559 - val_loss: 0.7098\n",
            "Epoch 4/5\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6146 - loss: 0.6555 - val_accuracy: 0.6785 - val_loss: 0.6019\n",
            "Epoch 5/5\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.6719 - loss: 0.5958 - val_accuracy: 0.7418 - val_loss: 0.5887\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a5653be3500>"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Set Trainable\n",
        "for layer in modelAB.layers[:-1]:\n",
        "    layer.trainable = True"
      ],
      "metadata": {
        "id": "YSZZhOkHxLvc"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelAB.fit(X_train_B, y_train_B, epochs=20,\n",
        "            validation_data=(X_valid_B, y_valid_B))"
      ],
      "metadata": {
        "id": "PrHqMkntxRtw",
        "outputId": "e6d559a3-9037-4dd3-e02e-67a050eff5cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7024 - loss: 0.5880 - val_accuracy: 0.7606 - val_loss: 0.5820\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7317 - loss: 0.5810 - val_accuracy: 0.7755 - val_loss: 0.5753\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7317 - loss: 0.5732 - val_accuracy: 0.7883 - val_loss: 0.5687\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7380 - loss: 0.5653 - val_accuracy: 0.7943 - val_loss: 0.5623\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7555 - loss: 0.5575 - val_accuracy: 0.8032 - val_loss: 0.5560\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7636 - loss: 0.5498 - val_accuracy: 0.8061 - val_loss: 0.5499\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7921 - loss: 0.5424 - val_accuracy: 0.8131 - val_loss: 0.5439\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7921 - loss: 0.5352 - val_accuracy: 0.8220 - val_loss: 0.5381\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8029 - loss: 0.5282 - val_accuracy: 0.8239 - val_loss: 0.5324\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8187 - loss: 0.5214 - val_accuracy: 0.8299 - val_loss: 0.5269\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8237 - loss: 0.5148 - val_accuracy: 0.8348 - val_loss: 0.5216\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8237 - loss: 0.5084 - val_accuracy: 0.8417 - val_loss: 0.5163\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8273 - loss: 0.5021 - val_accuracy: 0.8457 - val_loss: 0.5113\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8273 - loss: 0.4960 - val_accuracy: 0.8506 - val_loss: 0.5063\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8342 - loss: 0.4901 - val_accuracy: 0.8536 - val_loss: 0.5015\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8627 - loss: 0.4843 - val_accuracy: 0.8576 - val_loss: 0.4968\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8715 - loss: 0.4787 - val_accuracy: 0.8625 - val_loss: 0.4922\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8803 - loss: 0.4732 - val_accuracy: 0.8675 - val_loss: 0.4878\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8830 - loss: 0.4679 - val_accuracy: 0.8704 - val_loss: 0.4834\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8880 - loss: 0.4627 - val_accuracy: 0.8754 - val_loss: 0.4792\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a5653a67980>"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZqYFhEt681J"
      },
      "source": [
        "So, what's the final verdict?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "Ji5bmhSX681J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f24673a-7f14-4f82-beba-4bf206a2deb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8755 - loss: 0.4775\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4864097237586975, 0.8644999861717224]"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "#Evaluate\n",
        "modelAB.evaluate(X_test_B, y_test_B)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEngbali681J"
      },
      "source": [
        "Great! We got a bit of transfer: the model's accuracy went up 2 percentage points, from 89.7% to 92.25%. This means the error rate dropped by almost 25%:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "F-2yhuXj681J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16f60cfe-d7cc-47f0-f9fe-0cb2c2ea725f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.24757281553398036"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "1 - (100 - 92.25) / (100 -89.7)"
      ]
    }
  ]
}