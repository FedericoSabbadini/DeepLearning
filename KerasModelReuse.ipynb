{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FedericoSabbadini/DeepLearning/blob/main/KerasModelReuse.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "KdAi0sGq680i"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFNvCCSd680i"
      },
      "source": [
        "This project requires Python 3.7 or above:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JAmaeIFg680j"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "assert sys.version_info >= (3, 7)\n",
        "\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzJaazlL680m"
      },
      "source": [
        "And TensorFlow ≥ 2.8:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jLJZmpFf680n"
      },
      "outputs": [],
      "source": [
        "from packaging import version\n",
        "import tensorflow as tf\n",
        "\n",
        "assert version.parse(tf.__version__) >= version.parse(\"2.8.0\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YqEDo4y680o"
      },
      "source": [
        "As we did in previous chapters, let's define the default font sizes to make the figures prettier:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "O8TCzYLQ680o"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rc('font', size=14)\n",
        "plt.rc('axes', labelsize=14, titlesize=14)\n",
        "plt.rc('legend', fontsize=14)\n",
        "plt.rc('xtick', labelsize=10)\n",
        "plt.rc('ytick', labelsize=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MArCeZd680p"
      },
      "source": [
        "And let's create the `images/deep` folder (if it doesn't already exist), and define the `save_fig()` function which is used through this notebook to save the figures in high-res for the book:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GxyA8qMJ680p"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "IMAGES_PATH = Path() / \"images\" / \"deep\"\n",
        "IMAGES_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = IMAGES_PATH / f\"{fig_id}.{fig_extension}\"\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
        "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
      ],
      "metadata": {
        "id": "3Lgo_VNGaTDT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "FW4ATSKY680z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee381ef9-a0bc-430a-db64-9aafdd0c62ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "fashion_mnist = tf.keras.datasets.fashion_mnist.load_data()\n",
        "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist\n",
        "X_train, y_train = X_train_full[:-5000], y_train_full[:-5000]\n",
        "X_valid, y_valid = X_train_full[-5000:], y_train_full[-5000:]\n",
        "X_train, X_valid, X_test = X_train / 255, X_valid / 255, X_test / 255"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape\n",
        "# X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29zQ_joooRKz",
        "outputId": "c087638e-4fb3-4a43-bb4f-04d6fed7dab8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(55000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PJ6XCcs681F"
      },
      "source": [
        "# Reusing Pretrained Layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjTdvvhY681F"
      },
      "source": [
        "### Reusing a Keras model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AynifTS681F"
      },
      "source": [
        "Let's split the fashion MNIST training set in two:\n",
        "* `X_train_A`: all images of all items except for T-shirts/tops and pullovers (classes 0 and 2).\n",
        "* `X_train_B`: a much smaller training set of just the first 200 images of T-shirts/tops and pullovers.\n",
        "\n",
        "The validation set and the test set are also split this way, but without restricting the number of images.\n",
        "\n",
        "We will train a model on set A (classification task with 8 classes), and try to reuse it to tackle set B (binary classification). We hope to transfer a little bit of knowledge from task A to task B, since classes in set A (trousers, dresses, coats, sandals, shirts, sneakers, bags, and ankle boots) are somewhat similar to classes in set B (T-shirts/tops and pullovers). However, since we are using `Dense` layers, only patterns that occur at the same location can be reused (in contrast, convolutional layers will transfer much better, since learned patterns can be detected anywhere on the image, as we will see in the chapter 14)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Model A"
      ],
      "metadata": {
        "id": "kxw4oRsXZCp6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "v3oBTAUK681F"
      },
      "outputs": [],
      "source": [
        "# extra code – split Fashion MNIST into tasks A and B, then train and save\n",
        "#              model A to \"my_model_A\".\n",
        "\n",
        "pos_class_id = class_names.index(\"Pullover\")\n",
        "neg_class_id = class_names.index(\"T-shirt/top\")\n",
        "\n",
        "def split_dataset(X, y):\n",
        "    y_for_B = (y == pos_class_id) | (y == neg_class_id)\n",
        "    y_A = y[~y_for_B]\n",
        "    y_B = (y[y_for_B] == pos_class_id).astype(np.float32)\n",
        "    old_class_ids = list(set(range(10)) - set([neg_class_id, pos_class_id]))\n",
        "    for old_class_id, new_class_id in zip(old_class_ids, range(8)):\n",
        "        y_A[y_A == old_class_id] = new_class_id  # reorder class ids for A\n",
        "    return ((X[~y_for_B], y_A), (X[y_for_B], y_B))\n",
        "\n",
        "(X_train_A, y_train_A), (X_train_B, y_train_B) = split_dataset(X_train, y_train)\n",
        "(X_valid_A, y_valid_A), (X_valid_B, y_valid_B) = split_dataset(X_valid, y_valid)\n",
        "(X_test_A, y_test_A), (X_test_B, y_test_B) = split_dataset(X_test, y_test)\n",
        "X_train_B = X_train_B[:200]\n",
        "y_train_B = y_train_B[:200]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_A.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHVSPAzFpaYZ",
        "outputId": "19ba866e-6e59-4fd5-bd1e-4577a0f33f8a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(44011, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(43)\n",
        "\n",
        "model_A = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\",\n",
        "                          kernel_initializer=\"he_normal\"),\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\",\n",
        "                          kernel_initializer=\"he_normal\"),\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\",\n",
        "                          kernel_initializer=\"he_normal\"),\n",
        "    tf.keras.layers.Dense(8, activation=\"softmax\") # 8 classi finali, serve distribuzione di probabilità con softmax\n",
        "])\n",
        "\n",
        "model_A.compile(loss=\"sparse_categorical_crossentropy\", # con sparse converte gli 8 in un vettore\n",
        "                optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),\n",
        "                metrics=[\"accuracy\"]) # meglio altra metrica se non bilanciate, qua lo sono\n",
        "history = model_A.fit(X_train_A, y_train_A, epochs=20,\n",
        "                      validation_data=(X_valid_A, y_valid_A))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjqQsqMypLMd",
        "outputId": "7bac51d0-dbda-4605-d29d-17d787291369"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.4700 - loss: 1.5771 - val_accuracy: 0.8381 - val_loss: 0.4795\n",
            "Epoch 2/20\n",
            "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7307 - loss: 0.7680 - val_accuracy: 0.8561 - val_loss: 0.4004\n",
            "Epoch 3/20\n",
            "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7735 - loss: 0.6463 - val_accuracy: 0.8656 - val_loss: 0.3676\n",
            "Epoch 4/20\n",
            "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7981 - loss: 0.5773 - val_accuracy: 0.8762 - val_loss: 0.3397\n",
            "Epoch 5/20\n",
            "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8147 - loss: 0.5350 - val_accuracy: 0.8797 - val_loss: 0.3226\n",
            "Epoch 6/20\n",
            "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8255 - loss: 0.5105 - val_accuracy: 0.8844 - val_loss: 0.3167\n",
            "Epoch 7/20\n",
            "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8339 - loss: 0.4891 - val_accuracy: 0.8897 - val_loss: 0.3018\n",
            "Epoch 8/20\n",
            "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8394 - loss: 0.4659 - val_accuracy: 0.8952 - val_loss: 0.2931\n",
            "Epoch 9/20\n",
            "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8477 - loss: 0.4490 - val_accuracy: 0.8952 - val_loss: 0.2896\n",
            "Epoch 10/20\n",
            "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8508 - loss: 0.4356 - val_accuracy: 0.8957 - val_loss: 0.2875\n",
            "Epoch 11/20\n",
            "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8580 - loss: 0.4227 - val_accuracy: 0.8972 - val_loss: 0.2790\n",
            "Epoch 12/20\n",
            "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8567 - loss: 0.4098 - val_accuracy: 0.9012 - val_loss: 0.2738\n",
            "Epoch 13/20\n",
            "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8619 - loss: 0.4007 - val_accuracy: 0.9042 - val_loss: 0.2715\n",
            "Epoch 14/20\n",
            "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8676 - loss: 0.3947 - val_accuracy: 0.9030 - val_loss: 0.2716\n",
            "Epoch 15/20\n",
            "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8670 - loss: 0.3951 - val_accuracy: 0.9055 - val_loss: 0.2663\n",
            "Epoch 16/20\n",
            "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8713 - loss: 0.3798 - val_accuracy: 0.9062 - val_loss: 0.2621\n",
            "Epoch 17/20\n",
            "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8739 - loss: 0.3773 - val_accuracy: 0.9065 - val_loss: 0.2620\n",
            "Epoch 18/20\n",
            "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8735 - loss: 0.3758 - val_accuracy: 0.9077 - val_loss: 0.2585\n",
            "Epoch 19/20\n",
            "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8772 - loss: 0.3689 - val_accuracy: 0.9118 - val_loss: 0.2573\n",
            "Epoch 20/20\n",
            "\u001b[1m1376/1376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8787 - loss: 0.3574 - val_accuracy: 0.9118 - val_loss: 0.2551\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "( 1376 sono i batch (32 batch, default) eseguiti in sequenza. Aumentando i batch il numero di iterazioni per epoca diminuisce, ma richiede più tempo per processare più dati. )"
      ],
      "metadata": {
        "id": "aEjERr_Eq8QX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_A.evaluate(X_test_A, y_test_A)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9B9hcUnbQgc",
        "outputId": "3093583b-877a-47e1-b9dd-cb57fbbef7c1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9000 - loss: 0.2734\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.27295252680778503, 0.8987500071525574]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model B reaches 89.8% accuracy on its test set."
      ],
      "metadata": {
        "id": "nqK8Ks3kglg1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_A.save(\"my_model_A.keras\")"
      ],
      "metadata": {
        "id": "6gyNZyEIbtpU"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Model B"
      ],
      "metadata": {
        "id": "hiDMv8DvZI_m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "_mqjP0Xl681G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37d8c846-1fd7-495f-a93d-36992aff3e13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 224ms/step - accuracy: 0.4182 - loss: 0.7235 - val_accuracy: 0.4718 - val_loss: 0.6988\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5140 - loss: 0.6988 - val_accuracy: 0.5183 - val_loss: 0.6786\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5717 - loss: 0.6770 - val_accuracy: 0.5836 - val_loss: 0.6607\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6246 - loss: 0.6577 - val_accuracy: 0.6370 - val_loss: 0.6447\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6646 - loss: 0.6402 - val_accuracy: 0.6864 - val_loss: 0.6298\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7244 - loss: 0.6238 - val_accuracy: 0.7290 - val_loss: 0.6158\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7952 - loss: 0.6081 - val_accuracy: 0.7685 - val_loss: 0.6025\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8662 - loss: 0.5929 - val_accuracy: 0.7972 - val_loss: 0.5897\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8932 - loss: 0.5786 - val_accuracy: 0.8190 - val_loss: 0.5774\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8883 - loss: 0.5651 - val_accuracy: 0.8417 - val_loss: 0.5655\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9079 - loss: 0.5521 - val_accuracy: 0.8645 - val_loss: 0.5540\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9148 - loss: 0.5394 - val_accuracy: 0.8754 - val_loss: 0.5428\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9284 - loss: 0.5271 - val_accuracy: 0.8853 - val_loss: 0.5320\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9480 - loss: 0.5152 - val_accuracy: 0.8952 - val_loss: 0.5217\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9576 - loss: 0.5038 - val_accuracy: 0.9021 - val_loss: 0.5116\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9576 - loss: 0.4928 - val_accuracy: 0.9080 - val_loss: 0.5018\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9595 - loss: 0.4819 - val_accuracy: 0.9130 - val_loss: 0.4923\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9559 - loss: 0.4712 - val_accuracy: 0.9199 - val_loss: 0.4831\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9559 - loss: 0.4609 - val_accuracy: 0.9219 - val_loss: 0.4743\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9559 - loss: 0.4510 - val_accuracy: 0.9228 - val_loss: 0.4658\n"
          ]
        }
      ],
      "source": [
        "# extra code – train and evaluate model B, without reusing model A\n",
        "\n",
        "tf.random.set_seed(43)\n",
        "model_B = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\",\n",
        "                          kernel_initializer=\"he_normal\"),\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\",\n",
        "                          kernel_initializer=\"he_normal\"),\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\",\n",
        "                          kernel_initializer=\"he_normal\"),\n",
        "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model_B.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),\n",
        "                metrics=[\"accuracy\"])\n",
        "history = model_B.fit(X_train_B, y_train_B, epochs=20,\n",
        "                      validation_data=(X_valid_B, y_valid_B))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_B.evaluate(X_test_B, y_test_B)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eq1eTyDxb21E",
        "outputId": "4b32df04-44ac-43fa-f765-29f710b3579e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9185 - loss: 0.4706\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.47171345353126526, 0.9139999747276306]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qdg4deaF681G"
      },
      "source": [
        "Model B reaches 89.7% accuracy on the test set. Now let's try reusing the pretrained model A."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reuse Model A"
      ],
      "metadata": {
        "id": "oG7XlOSjZNDS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "_HsIAVmw681H"
      },
      "outputs": [],
      "source": [
        "model_A = tf.keras.models.load_model(\"my_model_A.keras\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSdisWQM681H"
      },
      "source": [
        "Note that `model_B_on_A` and `model_A` actually share layers now, so when we train one, it will update both models. If we want to avoid that, we need to build `model_B_on_A` on top of a *clone* of `model_A`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Ou8b6G2P681H"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(43)  # extra code – ensure reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "aLxJszNa681H"
      },
      "outputs": [],
      "source": [
        "model_A_clone = tf.keras.models.clone_model(model_A)\n",
        "model_A_clone.set_weights(model_A.get_weights())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "9QJG1c3i681I"
      },
      "outputs": [],
      "source": [
        "# extra code – creating model_B_on_A just like in the previous cell\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Fpy8IseK681I"
      },
      "outputs": [],
      "source": [
        "#Not trainable layers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "WxFsfvE9681I"
      },
      "outputs": [],
      "source": [
        "#Fit\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Set Trainable"
      ],
      "metadata": {
        "id": "KNkGMrcdiOuP"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZqYFhEt681J"
      },
      "source": [
        "So, what's the final verdict?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Ji5bmhSX681J"
      },
      "outputs": [],
      "source": [
        "#Evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEngbali681J"
      },
      "source": [
        "Great! We got a bit of transfer: the model's accuracy went up 2 percentage points, from 89.7% to 92.25%. This means the error rate dropped by almost 25%:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "F-2yhuXj681J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e42ec104-bf12-4bc6-bc40-ee76c504bdb4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.24757281553398036"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "1 - (100 - 92.25) / (100 -89.7)"
      ]
    }
  ]
}