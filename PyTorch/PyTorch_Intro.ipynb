{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FedericoSabbadini/DeepLearning/blob/main/PyTorch/PyTorch_Intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYouMsbZYWtC"
      },
      "source": [
        "# Introduzione a PyTorch\n",
        "\n",
        "## **What is PyTorch?**\n",
        "\n",
        "PyTorch is an open-source deep learning framework developed by Facebook’s AI Research team (FAIR). It's particularly popular for its flexibility and usability in research and production alike. Unlike TensorFlow's older versions, which used static computation graphs, PyTorch uses dynamic computation graphs, making it easier to debug and more intuitive for Python programmers.\n",
        "\n",
        "In this notebook, we will explore PyTorch's key features, followed by comparisons to Keras and TensorFlow.\n",
        "\n",
        "**Resources**\n",
        "\n",
        "- [PyTorch Documentation](https://pytorch.org/docs/)\n",
        "- [Keras Documentation](https://keras.io/)\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "## **Installing PyTorch**\n",
        "\n",
        "Since we're on Colab, we have nothing to do.\n",
        "But if you are interested in running it locally, you can follow the instructions from [PyTorch's official website](https://pytorch.org/get-started/locally/) to choose the correct version for CPU or GPU.\n",
        "\n",
        "\n",
        "```bash\n",
        "pip install torch torchvision torchaudio\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6i3DSLlYWtF"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "### **Tensors: The Building Block of PyTorch**\n",
        "\n",
        "In PyTorch, tensors are the fundamental data structure, analogous to arrays in NumPy but with the added advantage that they can run on GPUs. In this section, we’ll explore various ways to create tensors and some basic operations that can be performed on them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "id": "SrK8gQRhYWtF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ede6dae8-8429-466f-aea7-373c6056c7f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumPy array: \n",
            " [[1. 2.]\n",
            " [3. 4.]]\n",
            "\n",
            "Tensor from list:\n",
            " tensor([[1., 2.],\n",
            "        [3., 4.]])\n",
            "\n",
            "Tensor from NumPy array:\n",
            " tensor([[1., 2.],\n",
            "        [3., 4.]], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "DATA = [[1.0, 2.0], [3.0, 4.0]]\n",
        "\n",
        "np_array = np.array(DATA)\n",
        "print(f\"NumPy array: \\n {np_array}\")\n",
        "\n",
        "tensor_from_list = torch.tensor(DATA, dtype=torch.float32)\n",
        "print(f\"\\nTensor from list:\\n {tensor_from_list}\")\n",
        "\n",
        "tensor_from_numpy = torch.tensor(np_array)\n",
        "print(f\"\\nTensor from NumPy array:\\n {tensor_from_numpy}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TKtCp0DYWtH"
      },
      "source": [
        "**Creating Tensors with Special Initialization**\n",
        "\n",
        "PyTorch provides several functions to create tensors with specific initial values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "id": "h6SRsAmKYWtH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "066739bb-7ee7-4947-d0f7-5c6f6b2b9993"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor of zeros:\n",
            " tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "\n",
            "Tensor of ones:\n",
            " tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "\n",
            "Random tensor:\n",
            " tensor([[0.7804, 0.3562, 0.5606],\n",
            "        [0.1965, 0.4059, 0.3193]])\n",
            "\n",
            "Random tensor with the same shape as the previous tensor:\n",
            " tensor([[0.7134, 0.7668, 0.6382],\n",
            "        [0.2820, 0.7273, 0.0621]])\n"
          ]
        }
      ],
      "source": [
        "# Creating a tensor of zeros\n",
        "zeros_tensor = torch.zeros((2,3))\n",
        "print(f\"Tensor of zeros:\\n {zeros_tensor}\")\n",
        "\n",
        "# Creating a tensor of ones\n",
        "ones_tensor = torch.ones((2,3))\n",
        "print(f\"\\nTensor of ones:\\n {ones_tensor}\")\n",
        "\n",
        "# Creating a tensor with random values\n",
        "random_tensor = torch.rand(2,3)\n",
        "print(f\"\\nRandom tensor:\\n {random_tensor}\")\n",
        "\n",
        "rand_like_tensor = torch.rand_like(random_tensor) # causale che eredita le dimensioni da un altro\n",
        "print(f\"\\nRandom tensor with the same shape as the previous tensor:\\n {rand_like_tensor}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QbFM2MJYWtH"
      },
      "source": [
        "**Moving Tensors Between Devices (CPU and GPU)**\n",
        "\n",
        "One of the key advantages of PyTorch is its seamless support for GPU acceleration. PyTorch allows tensors to be created on or moved between devices like CPUs and GPUs. This is done using the ```torch.device()``` object and the ```to()``` method. If a GPU is available, computations *can* be much faster."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from time import time\n",
        "\n",
        "# Check if GPU is available\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu' #:0 significa la prima gpu disponibile, più efficiente\n",
        "print(f\"Using device: {device}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RM4vIubh7s7",
        "outputId": "66ea8ffb-ff0d-4fe1-9c0a-ef38fec5ea15"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda:0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkvNJSbwtMy9",
        "outputId": "0829a8e3-d799-4d14-ffd3-2b2dfee91a54"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Oct  3 10:54:29 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   76C    P0             30W /   70W |     126MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "id": "V9VBic4iYWtH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3f19cfb-3864-4298-9aed-623a6db1c30c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor on GPU (if available):\n",
            " tensor([[0.2963, 0.5811, 0.1909],\n",
            "        [0.7734, 0.1190, 0.3650]], device='cuda:0')\n",
            "\n",
            "Time taken on CPU: 0.183582 ms\n",
            "Time taken on GPU: 0.247478 ms\n"
          ]
        }
      ],
      "source": [
        "tensor_on_gpu = torch.rand((2, 3), device=device )\n",
        "print(\"Tensor on GPU (if available):\\n\", tensor_on_gpu)\n",
        "\n",
        "\n",
        "# Moving a tensor from CPU to GPU\n",
        "tensor_cpu = torch.ones((2, 3))\n",
        "\n",
        "s = time()\n",
        "result = tensor_cpu ** 2 * tensor_cpu ** 5\n",
        "print(f\"\\nTime taken on CPU: {round((time() - s)*1000, 6)} ms\")\n",
        "\n",
        "tensor_gpu = tensor_cpu.to(device)\n",
        "s = time()\n",
        "result = tensor_gpu ** 2 * tensor_gpu ** 5\n",
        "print(f\"Time taken on GPU: {round((time() - s)*1000, 6)} ms\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsDyu4MnYWtI"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "### **Automatic Differentiation: PyTorch’s Autograd**\n",
        "\n",
        "In deep learning, we often need to calculate gradients during backpropagation to update the weights of a neural network. [PyTorch’s autograd module](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html) is responsible for automatically computing the gradients of tensors during the backward pass. It does this by building a [dynamic computational graph](https://pytorch.org/blog/computational-graphs-constructed-in-pytorch/), where nodes represent operations and edges represent the flow of data.\n",
        "\n",
        "PyTorch tracks every operation on tensors with ```requires_grad=True``` to enable automatic differentiation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quando addestriamo un modello, come una rete neurale, dobbiamo calcolare i gradienti per ottimizzare i pesi. Per fare ciò, dobbiamo conoscere come i pesi influenzano l'output, e questo richiede il tracciamento delle operazioni che vengono eseguite sui tensori.\n",
        "\n",
        "PyTorch costruisce un grafo computazionale dinamico: ogni operazione che esegui su un tensore con requires_grad=True (come nel tuo esempio) viene registrata in un grafo. Questo grafo rappresenta le dipendenze tra le variabili, cioè come ogni variabile dipende dalle altre. Quando calcoli la perdita (ad esempio, la differenza tra le previsioni e i valori reali), PyTorch può eseguire il backpropagation e calcolare i gradienti lungo il grafo.\n",
        "Durante la fase di inferenza (quando il modello è già addestrato e viene utilizzato per fare previsioni), non è necessario calcolare i gradienti. In questa fase, vuoi solo eseguire le operazioni in modo più veloce. Ecco perché puoi disabilitare il tracciamento dei gradienti con torch.no_grad() per evitare un overhead computazionale inutile."
      ],
      "metadata": {
        "id": "N8UWjEONkEPT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {
        "id": "oGH4Y6gcYWtI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5afbc9a-4aa2-4aa8-cec7-94758e2238f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results: 14.0 \n",
            "\n",
            "Gradients of x: None\n",
            "Backward Function of y: None\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "x = torch.tensor([2.0, 3.0])\n",
        "\n",
        "y = x[0] ** 3 + x[1] * 2\n",
        "\n",
        "print(f\"Results: {y} \\n\")\n",
        "\n",
        "print(f\"Gradients of x: {x.grad}\")\n",
        "print(f\"Backward Function of y: {y.grad_fn}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "id": "TS6_AGkMYWtI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e940d26a-d123-4fb9-cceb-d0e80dc4ad7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "With gradient tracking 0.168324 ms\n",
            "Without gradient tracking 0.027895 ms\n"
          ]
        }
      ],
      "source": [
        "# Create a tensor with requires_grad=True\n",
        "a = torch.tensor([1.0, 2.0, 3.0], requires_grad=True) # si costruisce il grafo. per eseguirlo fare a.backward()\n",
        "\n",
        "# Perform operations with gradient tracking\n",
        "s = time()\n",
        "b = a ** 2\n",
        "print(f\"With gradient tracking {round((time() - s)*1000, 6)} ms\")\n",
        "\n",
        "# Disable gradient tracking\n",
        "with torch.no_grad():\n",
        "    s = time()\n",
        "    c = a ** 2\n",
        "    print(f\"Without gradient tracking {round((time() - s)*1000, 6)} ms\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMGHFkTEYWtJ"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "### **Building a Simple Neural Network in PyTorch**\n",
        "\n",
        "In this section, we will walk through the process of creating a simple neural network using PyTorch. All the components needed to build the network are contained in the [torch.nn](https://pytorch.org/docs/stable/nn.html) package."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {
        "id": "Eh4MrFqiYWtJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "outputId": "78cf46f4-c649-474d-967f-8a4284c77f08"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_10\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_10\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │            \u001b[38;5;34m12\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m5\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m17\u001b[0m (68.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> (68.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m17\u001b[0m (68.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> (68.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step\n",
            "\n",
            "Forward Pass: [[0.19302483]] in 238.548517 ms\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "\n",
        "INPUT = np.array([[1.0, 2.0]])\n",
        "\n",
        "# Define a simple network using Keras\n",
        "model = Sequential([\n",
        "    Input((2,)),\n",
        "    Dense(4, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "s = time()\n",
        "print(f\"\\nForward Pass: {model.predict(INPUT)} in {round((time() - s)*1000, 6)} ms\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "id": "-xUz27aIYWtJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4afe623d-027c-4a39-9590-ce513f532f60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=2, out_features=4, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=4, out_features=1, bias=True)\n",
            ")\n",
            "\n",
            "Forward Pass: tensor([[0.5272]], grad_fn=<AddmmBackward0>) in 1.049757 ms\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "INPUT = torch.tensor([[1.0, 2.0]])\n",
        "\n",
        "net = nn.Sequential(\n",
        "    nn.Linear(2, 4), # richiede definizione numero ingressi e uscite\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(4, 1)\n",
        ")\n",
        "\n",
        "print(net)\n",
        "\n",
        "s = time()\n",
        "print(f\"\\nForward Pass: {net(INPUT)} in {round((time() - s)*1000, 6)} ms\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-8IhCJ3YWtJ"
      },
      "source": [
        "PyTorch neural networks are typically defined by subclassing torch.nn.Module, which represents a base class for all neural networks in PyTorch. Layers are defined in the ```__init__()``` method, and the forward pass is implemented in the ```forward()``` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {
        "id": "Qpeq742CYWtJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5df58863-8421-4e0a-f169-65867fe27d8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimpleNet(\n",
            "  (fc1): Linear(in_features=2, out_features=4, bias=True)\n",
            "  (fc2): Linear(in_features=4, out_features=1, bias=True)\n",
            "  (relu): ReLU()\n",
            ")\n",
            "\n",
            "Forward Pass: tensor([[-0.4968]], grad_fn=<AddmmBackward0>) in 1.214743 ms\n"
          ]
        }
      ],
      "source": [
        "class SimpleNet(nn.Module):\n",
        "\n",
        "  def __init__(self, input_dim, output_dim, hidden_dim): # costruttore, definizione dei layer\n",
        "    super(SimpleNet, self).__init__()\n",
        "    self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "    self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "  def forward(self, x): # come fluiscono le informazioni nella nn tra i layer\n",
        "    x = self.fc1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.fc2(x)\n",
        "    return x\n",
        "\n",
        "net = SimpleNet(input_dim=2, output_dim=1, hidden_dim=4)\n",
        "\n",
        "print(net)\n",
        "\n",
        "s = time()\n",
        "print(f\"\\nForward Pass: {net(INPUT)} in {round((time() - s)*1000, 6)} ms\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7l_qqUeYWtJ"
      },
      "source": [
        "**Training a Neural Network in PyTorch**\n",
        "\n",
        "PyTorch is a powerful deep learning library that gives us a high degree of manual control over every step of the training process. Unlike Keras, which abstracts many of the internal workings behind easy-to-use functions, PyTorch allows us to customize every part of the model’s behavior. This can be especially useful when we need to fine-tune specific aspects of the training or modify the underlying logic to fit complex or non-standard tasks.\n",
        "\n",
        "We will begin by setting up a basic neural network model, define the [loss function](https://pytorch.org/docs/stable/nn.html#loss-functions), and then proceed with training the network on a dataset. As we go, we'll manually implement essential components such as forward passes, backpropagation, and weight updates with [optimizer](https://pytorch.org/docs/stable/optim.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {
        "id": "IDXSCb-AYWtJ"
      },
      "outputs": [],
      "source": [
        "# Define loss function and optimizer\n",
        "\n",
        "net = SimpleNet(input_dim=2, output_dim=1, hidden_dim=4)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
        "\n",
        "# Train the network to understand if the input is positive or negative\n",
        "\n",
        "train_dataset = [\n",
        "    (torch.tensor([1.0, 2.0]), torch.tensor([1.0])),\n",
        "    (torch.tensor([-3.0, -4.0]), torch.tensor([0.0])),\n",
        "    (torch.tensor([5.0, 6.0]), torch.tensor([1.0])),\n",
        "    (torch.tensor([-5.0, -6.0]), torch.tensor([0.0])),\n",
        "]\n",
        "\n",
        "NUM_EPOCHS = 5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !!!!!!!!!!! comandi per addestramento di una rete !!!!!!!!!!!!!!!\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    for tensor, target in train_dataset:net.train\n",
        "    net.train()\n",
        "    output = net(tensor)\n",
        "    loss = criterion(output, target)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {round(loss.item(), 4)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pyJcSIQrSGJ",
        "outputId": "441c57b9-e229-47e9-f010-5ab6a1ce6829"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.1193\n",
            "Epoch 2, Loss: 0.0009\n",
            "Epoch 3, Loss: 0.0\n",
            "Epoch 4, Loss: 0.0\n",
            "Epoch 5, Loss: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IW0fP10EYWtK"
      },
      "source": [
        "## **PyTorch vs. TensorFlow/Keras**\n",
        "\n",
        "\n",
        "| Feature               | PyTorch                                    | TensorFlow/Keras                          |\n",
        "|-----------------------|--------------------------------------------|-------------------------------------------|\n",
        "| **API Level**          | Low-level, very flexible                   | High-level (Keras) or low-level (TF core) |\n",
        "| **Computation Graph**  | Dynamic (eager execution)                  | Dynamic (with TensorFlow 2.x)             |\n",
        "| **Ease of Use**        | More manual, but powerful                  | Keras is very user-friendly               |\n",
        "| **Community**          | Growing rapidly, dominant in research      | Strong support, widely adopted in industry|\n",
        "| **Ecosystem**          | Fewer add-ons (though fast-growing)        | Large ecosystem (e.g., TensorFlow Hub)    |\n",
        "\n",
        "<br>\n",
        "\n",
        "## **Conclusion**\n",
        "\n",
        "- PyTorch provides exceptional flexibility, making it a favorite for researchers.\n",
        "- TensorFlow has a mature ecosystem, but PyTorch’s dynamic nature is great for debugging and custom models.\n",
        "- Keras is best for beginners or when rapid prototyping is necessary.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}