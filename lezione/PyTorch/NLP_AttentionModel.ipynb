{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FedericoSabbadini/DeepLearning/blob/main/lezione/PyTorch/NLP_AttentionModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RdVDgxpHaSp"
      },
      "source": [
        "# **Encoder - Decoder for Natural Language Processing**\n",
        "\n",
        "In this exercise we will see how to implement a working Encoder-Decoder architecture to solve an English - Italian translation task.\n",
        "\n",
        "The following notebook will range from the pre-processing of data, the construction of a usable dataset to the design of an architecture based on RRNs and an Attention layer on top.\n",
        "\n",
        "---\n",
        "\n",
        "### **The Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BC3pw_gqoYNf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b2cf2bc-d4d9-4230-b0a2-c708a9c019be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-10-31 11:53:47--  https://www.manythings.org/anki/ita-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n",
            "Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8846174 (8.4M) [application/zip]\n",
            "Saving to: ‘ita-eng.zip’\n",
            "\n",
            "ita-eng.zip         100%[===================>]   8.44M  53.4MB/s    in 0.2s    \n",
            "\n",
            "2025-10-31 11:53:47 (53.4 MB/s) - ‘ita-eng.zip’ saved [8846174/8846174]\n",
            "\n",
            "Archive:  ita-eng.zip\n",
            "  inflating: ita.txt                 \n",
            "  inflating: _about.txt              \n"
          ]
        }
      ],
      "source": [
        "!wget https://www.manythings.org/anki/ita-eng.zip\n",
        "!unzip ita-eng.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Xc4AGz9Xpare"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "SEED = 124564\n",
        "\n",
        "def set_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "set_seed(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "s3xQJTR0HaS0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "13f7e96c-9efd-45e7-fcab-88429fb0d8e9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  english  \\\n",
              "0                                                     Hi.   \n",
              "1                                                     Hi.   \n",
              "2                                                    Run!   \n",
              "3                                                    Run!   \n",
              "4                                                    Run!   \n",
              "...                                                   ...   \n",
              "400008  I know that adding sentences only in your nati...   \n",
              "400009  I know that adding sentences only in your nati...   \n",
              "400010  I know that adding sentences only in your nati...   \n",
              "400011  Doubtless there exists in this world precisely...   \n",
              "400012  Doubtless there exists in this world precisely...   \n",
              "\n",
              "                                                  italian  \n",
              "0                                                   Ciao!  \n",
              "1                                                   Ciao.  \n",
              "2                                                  Corri!  \n",
              "3                                                  Corra!  \n",
              "4                                                Correte!  \n",
              "...                                                   ...  \n",
              "400008  So che aggiungere frasi soltanto nella sua lin...  \n",
              "400009  So che aggiungere frasi solamente nella sua li...  \n",
              "400010  So che aggiungere frasi solamente nella sua li...  \n",
              "400011  Senza dubbio esiste in questo mondo proprio la...  \n",
              "400012  Senza dubbio esiste in questo mondo proprio la...  \n",
              "\n",
              "[400013 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c11f25a7-9ce5-4b5f-b772-cfc102c2e3c6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english</th>\n",
              "      <th>italian</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Ciao!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Ciao.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Corri!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Corra!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Correte!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>400008</th>\n",
              "      <td>I know that adding sentences only in your nati...</td>\n",
              "      <td>So che aggiungere frasi soltanto nella sua lin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>400009</th>\n",
              "      <td>I know that adding sentences only in your nati...</td>\n",
              "      <td>So che aggiungere frasi solamente nella sua li...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>400010</th>\n",
              "      <td>I know that adding sentences only in your nati...</td>\n",
              "      <td>So che aggiungere frasi solamente nella sua li...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>400011</th>\n",
              "      <td>Doubtless there exists in this world precisely...</td>\n",
              "      <td>Senza dubbio esiste in questo mondo proprio la...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>400012</th>\n",
              "      <td>Doubtless there exists in this world precisely...</td>\n",
              "      <td>Senza dubbio esiste in questo mondo proprio la...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>400013 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c11f25a7-9ce5-4b5f-b772-cfc102c2e3c6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c11f25a7-9ce5-4b5f-b772-cfc102c2e3c6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c11f25a7-9ce5-4b5f-b772-cfc102c2e3c6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a2ea7ee0-4eb7-4f88-88f9-59b8b38187cb\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a2ea7ee0-4eb7-4f88-88f9-59b8b38187cb')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a2ea7ee0-4eb7-4f88-88f9-59b8b38187cb button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_50be06e2-009b-42e5-8fa2-2b5bfbcc485a\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_50be06e2-009b-42e5-8fa2-2b5bfbcc485a button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"ita.txt\", sep=\"\\t\", header=None, names=[\"english\", \"italian\", \"attrib\"])\n",
        "df.drop([\"attrib\"], axis=1, inplace=True)\n",
        "\n",
        "df = df.drop_duplicates().dropna().reset_index(drop=True)\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RI1A31lCk4f"
      },
      "source": [
        "**Creating the vocabulary**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4ZqGkDc9HaS4"
      },
      "outputs": [],
      "source": [
        "import unicodedata\n",
        "import re\n",
        "\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z]+\", r\" \", s)\n",
        "    return s.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "AsYBuNy3HaS5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f42ba9a-6434-42e9-95c3-6cb1c2b61dd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added 14036 English words and 28066 Italian words.\n"
          ]
        }
      ],
      "source": [
        "class Lang():\n",
        "\n",
        "    def __init__(self, name, initial_sentences):\n",
        "        self.name = name\n",
        "        # \"PAD\" = to pad all sequence to the same len\n",
        "        # \"SOS\" = sentence's start\n",
        "        # \"EOS\" = sentence's end\n",
        "        self.word2index = {\"PAD\": 0, \"SOS\": 1, \"EOS\": 2}\n",
        "        self.n_words = 3\n",
        "\n",
        "        for sentence in initial_sentences:\n",
        "            self.addSentence(sentence)\n",
        "\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        sentence = normalizeString(sentence)\n",
        "\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index.keys():\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.n_words += 1\n",
        "\n",
        "eng_lang = Lang(\"english\", df.english.tolist())\n",
        "ita_lang = Lang(\"italian\", df.italian.tolist())\n",
        "\n",
        "print(f\"Added {eng_lang.n_words} English words and {ita_lang.n_words} Italian words.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "HFYyCSUDHaS6"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "\n",
        "class TranslationDataset(Dataset):\n",
        "\n",
        "    def __init__(self, df, in_lang, out_lang, max_len):\n",
        "        self.df = df # coppie en-it\n",
        "        self.in_lang = in_lang\n",
        "        self.out_lang = out_lang\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        # Prepare input sentence.\n",
        "        inp_sent = normalizeString(self.df.iloc[idx][self.in_lang.name])\n",
        "\n",
        "        inp_list = inp_sent.split(' ')[:self.max_len-1] + [\"EOS\"]       # Truncation\n",
        "        inp_list = inp_list + [\"PAD\"]*(self.max_len - len(inp_list))    # Padding\n",
        "\n",
        "        inp_indexes = [self.in_lang.word2index[word] for word in inp_list]\n",
        "\n",
        "        # Prepare output sentence.\n",
        "        out_sent = normalizeString(self.df.iloc[idx][self.out_lang.name])\n",
        "\n",
        "        out_list = [\"SOS\"] + out_sent.split(' ')[:self.max_len-2] + [\"EOS\"]\n",
        "        out_list = out_list + [\"PAD\"]*(self.max_len - len(out_list))\n",
        "\n",
        "        out_indexes = [self.out_lang.word2index[word] for word in out_list]\n",
        "\n",
        "        return torch.tensor(inp_indexes, dtype=torch.long), torch.tensor(out_indexes, dtype=torch.long)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "oinIst8cHaS7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31076c84-398c-4193-9e67-413ce114a3f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#Train examples: 320010\n",
            "#Val   examples: 40001\n",
            "#Test  examples: 40002\n"
          ]
        }
      ],
      "source": [
        "df_train = df.sample(frac=0.8, random_state=SEED).reset_index(drop=True)\n",
        "\n",
        "df_test = df.drop(df_train.index).reset_index(drop=True)\n",
        "df_val = df_test.sample(frac=0.5, random_state=SEED).reset_index(drop=True)\n",
        "\n",
        "df_test = df_test.drop(df_val.index).reset_index(drop=True)\n",
        "\n",
        "\n",
        "print(f\"#Train examples: {len(df_train)}\")\n",
        "print(f\"#Val   examples: {len(df_test)}\")\n",
        "print(f\"#Test  examples: {len(df_val)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "d80SFdjDHaS8"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "MAX_LEN = 14\n",
        "BATCH_SIZE = 64 # 128 better\n",
        "\n",
        "input_lang = ita_lang\n",
        "output_lang = eng_lang\n",
        "\n",
        "train_dataset = TranslationDataset(df_train, input_lang, output_lang, MAX_LEN)\n",
        "val_dataset = TranslationDataset(df_val, input_lang, output_lang, MAX_LEN)\n",
        "test_dataset = TranslationDataset(df_test, input_lang, output_lang, MAX_LEN)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qowa3LIDHaS9"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "### **The Encoder-Decoder Architecture**\n",
        "\n",
        "Finally, in this section we will start coding our PyTorch architecture."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RNN Encoder**\n",
        "\n",
        "Reads the source sentence and produces its representation"
      ],
      "metadata": {
        "id": "-rL4s5m1FeqG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "x0lps1fsHaS-"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class EncoderRNN(nn.Module):\n",
        "\n",
        "  def __init__(self, vocab_size, embedding_size, hidden_size, dropout_p=0.1):\n",
        "    super(EncoderRNN, self).__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
        "    self.dropout = nn.Dropout(dropout_p)\n",
        "    self.gru = nn.GRU(embedding_size, hidden_size, batch_first=True)\n",
        "\n",
        "\n",
        "  def forward(self, input_tensor):\n",
        "    # input:  bs, seq_len, 1\n",
        "    # hidden: 1, bs, hs\n",
        "    # output: bs, seq_len, hs\n",
        "\n",
        "    embedded = self.dropout(self.embedding(input_tensor))\n",
        "    outputs, hidden = self.gru(embedded)\n",
        "    return outputs, hidden\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJPj9FkyHaS_"
      },
      "source": [
        "**RNN Decoder**\n",
        "\n",
        "Uses source representation from the encoder to generate the target sentence with the help of Attention module"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BahdanauAttention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "\n",
        "        self.Wa = nn.Linear(hidden_size, hidden_size) #W1\n",
        "        self.Ua = nn.Linear(hidden_size, hidden_size) #W2\n",
        "        self.Va = nn.Linear(hidden_size, 1)\n",
        "\n",
        "\n",
        "    def forward(self, last_decoder_output, encoder_outputs):\n",
        "        a = self.Wa(last_decoder_output)\n",
        "        b = self.Ua(encoder_outputs)\n",
        "        scores = self.Va(torch.tanh(a + b))\n",
        "        scores = scores.squeeze(2).unsqueeze(1)\n",
        "\n",
        "        weights = F.softmax(scores, dim=-1)\n",
        "        context = torch.bmm(weights, encoder_outputs)\n",
        "\n",
        "        return context, weights"
      ],
      "metadata": {
        "id": "RvDp125MFtLg"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "glIYu3m9HaTA"
      },
      "outputs": [],
      "source": [
        "class AttDecoderRNN(nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_size, hidden_size, output_size, dropout_p, max_len, device, sos_token_ind):\n",
        "        super(AttDecoderRNN, self).__init__()\n",
        "\n",
        "        self.max_len = max_len\n",
        "        self.device = device\n",
        "        self.sos_token_ind = sos_token_ind\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, embedding_size)\n",
        "        self.attention = BahdanauAttention(hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size + embedding_size, hidden_size, batch_first=True)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "\n",
        "    def forward_step(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "\n",
        "        # shape: hidden -> (1, batch_size, hidden_size) -- Attention need batch first!\n",
        "        context, attn_weights = self.attention(hidden.permute(1, 0, 2), encoder_outputs)\n",
        "\n",
        "        input_gru = torch.cat((embedded, context), dim=2)\n",
        "\n",
        "        output, hidden = self.gru(input_gru, hidden)\n",
        "        output = F.softmax(self.out(output), dim=-1)\n",
        "\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "\n",
        "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
        "        decoder_input = torch.tensor([[self.sos_token_ind]]*encoder_outputs.size(0),\n",
        "                                     dtype=torch.long,\n",
        "                                     device=self.device)\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoder_outputs = []\n",
        "        attentions = []\n",
        "\n",
        "        for i in range(self.max_len):\n",
        "            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n",
        "                decoder_input, decoder_hidden, encoder_outputs\n",
        "            )\n",
        "            decoder_outputs.append(decoder_output)\n",
        "            attentions.append(attn_weights)\n",
        "\n",
        "            # Teacher forcing: Feed the target as the next input\n",
        "            if target_tensor is not None:\n",
        "                decoder_input = target_tensor[:, i].unsqueeze(1)\n",
        "\n",
        "            # Without teacher forcing: use its own predictions as the next input\n",
        "            else:\n",
        "                _, topi = decoder_output.topk(1)\n",
        "                decoder_input = topi.squeeze(-1).detach()\n",
        "\n",
        "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
        "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
        "        attentions = torch.cat(attentions, dim=1)\n",
        "\n",
        "        return decoder_outputs, decoder_hidden, attentions\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "from tqdm import tqdm\n",
        "from torch.optim import Adam\n",
        "from torch.amp import GradScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "class EncoderDecoder(nn.Module):\n",
        "\n",
        "    def __init__(self, encoder, decoder, model_name, device):\n",
        "        super(EncoderDecoder, self).__init__()\n",
        "\n",
        "        self.model_name = model_name\n",
        "        self.device = device\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "\n",
        "    def forward(self, input_tensor, target_tensor):\n",
        "        encoder_outputs, encoder_hidden = self.encoder(input_tensor)\n",
        "        decoder_outputs, _, _ = self.decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
        "\n",
        "        return decoder_outputs\n",
        "\n",
        "\n",
        "    def train_architecture(self, train_data, val_data, epochs, criterion, optimizer, scaler):\n",
        "\n",
        "        train_losses = []\n",
        "        val_losses = []\n",
        "        accuracies = []\n",
        "        best_valloss = np.inf\n",
        "        best_ep = 0\n",
        "        best_model = copy.deepcopy(self.state_dict())\n",
        "\n",
        "        for ep in tqdm(range(epochs)):\n",
        "            self.train()\n",
        "            ep_loss = 0.0\n",
        "\n",
        "            for batch in train_data:\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                input_tensor, target_tensor = [b.to(self.device) for b in batch]\n",
        "\n",
        "                output_tensor = self(input_tensor, target_tensor)\n",
        "\n",
        "                # Flatten the tensor on the batch_size x seq_len:\n",
        "                # output_tensor: (64, 14, 27230) -> (896, 27230)\n",
        "                # target_tensor: (64, 14) -> (896)\n",
        "                loss = criterion(output_tensor.view(-1, output_tensor.size(-1)), target_tensor.view(-1))\n",
        "\n",
        "                ep_loss += loss.item()\n",
        "\n",
        "                # Backpropagation\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "\n",
        "            train_losses.append(ep_loss/len(train_data))\n",
        "\n",
        "            # Evaluation\n",
        "\n",
        "            val_loss, accuracy = self.eval_model(val_data, criterion)\n",
        "            accuracies.append(accuracy)\n",
        "            val_losses.append(val_loss)\n",
        "\n",
        "            if val_loss < best_valloss:\n",
        "                best_valloss = val_loss\n",
        "                best_model = copy.deepcopy(self.state_dict())\n",
        "                best_ep = ep+1\n",
        "\n",
        "            torch.save(best_model, f\"models/{self.model_name}.pth\")\n",
        "\n",
        "        return train_losses, accuracies, val_losses, best_ep, best_valloss\n",
        "\n",
        "\n",
        "    def eval_model(self, val_data, criterion):\n",
        "        self.eval()\n",
        "\n",
        "        val_loss = 0.0\n",
        "        val_preds = []\n",
        "        val_labels = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in val_data:\n",
        "                input_tensor, target_tensor = [b.to(self.device) for b in batch]\n",
        "\n",
        "                output_tensor = self(input_tensor, target_tensor)\n",
        "                loss = criterion(output_tensor.view(-1, output_tensor.size(-1)), target_tensor.view(-1))\n",
        "\n",
        "                predictions = output_tensor.argmax(dim=-1)\n",
        "\n",
        "                val_loss += loss.item()\n",
        "                val_preds.extend(predictions.cpu().numpy().flatten())\n",
        "                val_labels.extend(target_tensor.cpu().numpy().flatten())\n",
        "\n",
        "        return val_loss/len(val_data), accuracy_score(val_labels, val_preds)\n",
        "\n",
        "\n",
        "    def generate(self, test_data):\n",
        "        self.eval()\n",
        "\n",
        "        test_preds = []\n",
        "        test_labels = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in test_data:\n",
        "                input_tensor, target_tensor = [b.to(self.device) for b in batch]\n",
        "\n",
        "                output_tensor = self(input_tensor, target_tensor)\n",
        "                predictions = output_tensor.argmax(dim=-1)\n",
        "\n",
        "                test_preds.extend(predictions.cpu().numpy().flatten())\n",
        "                test_labels.extend(target_tensor.cpu().numpy().flatten())\n",
        "\n",
        "        return test_preds, test_labels"
      ],
      "metadata": {
        "id": "9vSmIm_GGaIT"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "!mkdir -p models\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Device loaded: {device}\")\n",
        "\n",
        "embedding_size = 128\n",
        "hidden_size = 256\n",
        "drop_rate = 0.1\n",
        "lr = 0.001\n",
        "epochs = 5\n",
        "\n",
        "sos_token = input_lang.word2index[\"SOS\"]\n",
        "pad_token = input_lang.word2index[\"PAD\"]\n",
        "\n",
        "criterion = nn.NLLLoss(ignore_index=pad_token)\n",
        "scaler = GradScaler()"
      ],
      "metadata": {
        "id": "UCLkwNCLF6iB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52ae316d-37ef-4886-b6f5-b44fb3b38416"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device loaded: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ETXTtkJiJFQW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d7e9543-5896-489c-e100-2e35f0807873"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training the model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [17:56<00:00, 215.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Best model at epoch 5 with val loss 9.1423\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "att_encoder = EncoderRNN(input_lang.n_words, embedding_size, hidden_size, drop_rate)\n",
        "att_decoder = AttDecoderRNN(embedding_size, hidden_size, output_lang.n_words, drop_rate, MAX_LEN, device, sos_token)\n",
        "\n",
        "att_model = EncoderDecoder(att_encoder, att_decoder, \"attention\", device).to(device)\n",
        "optimizer = Adam(att_model.parameters(), lr=lr)\n",
        "\n",
        "print(\"Training the model...\")\n",
        "att_train_losses, att_accuracies, att_val_losses, best_ep, best_valloss = att_model.train_architecture(train_loader, val_loader, epochs, criterion, optimizer, scaler)\n",
        "\n",
        "print(f\"\\n\\nBest model at epoch {best_ep} with val loss {round(best_valloss, 4)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "cF6JR_c-m2_Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "outputId": "f9b31c71-a2ad-4866-d868-43504fc4bb1c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(att_accuracies, label=\"Attention Model\")\n",
        "plt.ylim(0, 1)\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyqRDLd4HaTE"
      },
      "source": [
        "## Testing <br>\n",
        "BLEU (bilingual evaluation understudy) is an algorithm for evaluating the quality of text which has been machine-translated from one natural language to another. Quality is considered to be the correspondence between a machine's output and that of a human: \"the closer a machine translation is to a professional human translation, the better it is\".\n",
        "\n",
        "**BLEU's output is always a number between 0 and 1.** This value indicates how similar the candidate text is to the reference texts, with values closer to 1 representing more similar texts.\n",
        "\n",
        "\n",
        "*Documentation:*\n",
        "\n",
        " - [NLTK Implementation](https://www.nltk.org/_modules/nltk/translate/bleu_score.html)\n",
        " - [ SmoothingFunction](https://aclanthology.org/W14-3346.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "RjRXlsdiHaTE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f87b28b-bd8d-4d5b-d4ee-c0f243ea1fde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy for attention model: 31.04%\n",
            "Test BLEU Score for attention model: 0.14\n"
          ]
        }
      ],
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "\n",
        "def compute_bleu(labels, preds):\n",
        "    labels = np.reshape(labels, (round(len(test_preds)/MAX_LEN), MAX_LEN)).tolist()\n",
        "    preds = np.reshape(preds, (round(len(test_preds)/MAX_LEN), MAX_LEN)).tolist()\n",
        "\n",
        "    bleus = []\n",
        "    for ref, cand in zip(labels, preds):\n",
        "        bleus.append(sentence_bleu([ref], cand, weights=[0.25, 0.25, 0.25, 0.25], smoothing_function=SmoothingFunction().method7))\n",
        "\n",
        "    return sum(bleus)/len(bleus)\n",
        "\n",
        "\n",
        "att_model.load_state_dict(torch.load(f\"models/{att_model.model_name}.pth\", weights_only=False))\n",
        "test_preds, test_labels = att_model.generate(test_loader)\n",
        "\n",
        "print(f\"Test Accuracy for {att_model.model_name} model: {round(accuracy_score(test_labels, test_preds)*100, 2)}%\")\n",
        "print(f\"Test BLEU Score for {att_model.model_name} model: {round(compute_bleu(test_labels, test_preds), 2)}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}