{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FedericoSabbadini/DeepLearning/blob/main/NLP_AttentionModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RdVDgxpHaSp"
      },
      "source": [
        "# **Encoder - Decoder for Natural Language Processing**\n",
        "\n",
        "Author: Nicola Arici (nicola.arici@unibs.it)\n",
        "\n",
        "In this exercise we will see how to implement a working Encoder-Decoder architecture to solve an English - Italian translation task.\n",
        "\n",
        "The following notebook will range from the pre-processing of data, the construction of a usable dataset to the design of an architecture based on RRNs and an Attention layer on top.\n",
        "\n",
        "---\n",
        "\n",
        "### **The Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BC3pw_gqoYNf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b2cf2bc-d4d9-4230-b0a2-c708a9c019be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-10-31 11:53:47--  https://www.manythings.org/anki/ita-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n",
            "Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8846174 (8.4M) [application/zip]\n",
            "Saving to: ‘ita-eng.zip’\n",
            "\n",
            "ita-eng.zip         100%[===================>]   8.44M  53.4MB/s    in 0.2s    \n",
            "\n",
            "2025-10-31 11:53:47 (53.4 MB/s) - ‘ita-eng.zip’ saved [8846174/8846174]\n",
            "\n",
            "Archive:  ita-eng.zip\n",
            "  inflating: ita.txt                 \n",
            "  inflating: _about.txt              \n"
          ]
        }
      ],
      "source": [
        "!wget https://www.manythings.org/anki/ita-eng.zip\n",
        "!unzip ita-eng.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Xc4AGz9Xpare"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "SEED = 124564\n",
        "\n",
        "def set_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "set_seed(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "s3xQJTR0HaS0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "13f7e96c-9efd-45e7-fcab-88429fb0d8e9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  english  \\\n",
              "0                                                     Hi.   \n",
              "1                                                     Hi.   \n",
              "2                                                    Run!   \n",
              "3                                                    Run!   \n",
              "4                                                    Run!   \n",
              "...                                                   ...   \n",
              "400008  I know that adding sentences only in your nati...   \n",
              "400009  I know that adding sentences only in your nati...   \n",
              "400010  I know that adding sentences only in your nati...   \n",
              "400011  Doubtless there exists in this world precisely...   \n",
              "400012  Doubtless there exists in this world precisely...   \n",
              "\n",
              "                                                  italian  \n",
              "0                                                   Ciao!  \n",
              "1                                                   Ciao.  \n",
              "2                                                  Corri!  \n",
              "3                                                  Corra!  \n",
              "4                                                Correte!  \n",
              "...                                                   ...  \n",
              "400008  So che aggiungere frasi soltanto nella sua lin...  \n",
              "400009  So che aggiungere frasi solamente nella sua li...  \n",
              "400010  So che aggiungere frasi solamente nella sua li...  \n",
              "400011  Senza dubbio esiste in questo mondo proprio la...  \n",
              "400012  Senza dubbio esiste in questo mondo proprio la...  \n",
              "\n",
              "[400013 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c11f25a7-9ce5-4b5f-b772-cfc102c2e3c6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english</th>\n",
              "      <th>italian</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Ciao!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Ciao.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Corri!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Corra!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Correte!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>400008</th>\n",
              "      <td>I know that adding sentences only in your nati...</td>\n",
              "      <td>So che aggiungere frasi soltanto nella sua lin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>400009</th>\n",
              "      <td>I know that adding sentences only in your nati...</td>\n",
              "      <td>So che aggiungere frasi solamente nella sua li...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>400010</th>\n",
              "      <td>I know that adding sentences only in your nati...</td>\n",
              "      <td>So che aggiungere frasi solamente nella sua li...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>400011</th>\n",
              "      <td>Doubtless there exists in this world precisely...</td>\n",
              "      <td>Senza dubbio esiste in questo mondo proprio la...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>400012</th>\n",
              "      <td>Doubtless there exists in this world precisely...</td>\n",
              "      <td>Senza dubbio esiste in questo mondo proprio la...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>400013 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c11f25a7-9ce5-4b5f-b772-cfc102c2e3c6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c11f25a7-9ce5-4b5f-b772-cfc102c2e3c6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c11f25a7-9ce5-4b5f-b772-cfc102c2e3c6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a2ea7ee0-4eb7-4f88-88f9-59b8b38187cb\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a2ea7ee0-4eb7-4f88-88f9-59b8b38187cb')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a2ea7ee0-4eb7-4f88-88f9-59b8b38187cb button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_50be06e2-009b-42e5-8fa2-2b5bfbcc485a\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_50be06e2-009b-42e5-8fa2-2b5bfbcc485a button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"ita.txt\", sep=\"\\t\", header=None, names=[\"english\", \"italian\", \"attrib\"])\n",
        "df.drop([\"attrib\"], axis=1, inplace=True)\n",
        "\n",
        "df = df.drop_duplicates().dropna().reset_index(drop=True)\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RI1A31lCk4f"
      },
      "source": [
        "**Creating the vocabulary**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4ZqGkDc9HaS4"
      },
      "outputs": [],
      "source": [
        "import unicodedata\n",
        "import re\n",
        "\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z]+\", r\" \", s)\n",
        "    return s.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "AsYBuNy3HaS5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f42ba9a-6434-42e9-95c3-6cb1c2b61dd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added 14036 English words and 28066 Italian words.\n"
          ]
        }
      ],
      "source": [
        "class Lang():\n",
        "\n",
        "    def __init__(self, name, initial_sentences):\n",
        "        self.name = name\n",
        "        # \"PAD\" = to pad all sequence to the same len\n",
        "        # \"SOS\" = sentence's start\n",
        "        # \"EOS\" = sentence's end\n",
        "        self.word2index = {\"PAD\": 0, \"SOS\": 1, \"EOS\": 2}\n",
        "        self.n_words = 3\n",
        "\n",
        "        for sentence in initial_sentences:\n",
        "            self.addSentence(sentence)\n",
        "\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        sentence = normalizeString(sentence)\n",
        "\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index.keys():\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.n_words += 1\n",
        "\n",
        "eng_lang = Lang(\"english\", df.english.tolist())\n",
        "ita_lang = Lang(\"italian\", df.italian.tolist())\n",
        "\n",
        "print(f\"Added {eng_lang.n_words} English words and {ita_lang.n_words} Italian words.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "HFYyCSUDHaS6"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "\n",
        "class TranslationDataset(Dataset):\n",
        "\n",
        "    def __init__(self, df, in_lang, out_lang, max_len):\n",
        "        self.df = df # coppie en-it\n",
        "        self.in_lang = in_lang\n",
        "        self.out_lang = out_lang\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        # Prepare input sentence.\n",
        "        inp_sent = normalizeString(self.df.iloc[idx][self.in_lang.name])\n",
        "\n",
        "        inp_list = inp_sent.split(' ')[:self.max_len-1] + [\"EOS\"]       # Truncation\n",
        "        inp_list = inp_list + [\"PAD\"]*(self.max_len - len(inp_list))    # Padding\n",
        "\n",
        "        inp_indexes = [self.in_lang.word2index[word] for word in inp_list]\n",
        "\n",
        "        # Prepare output sentence.\n",
        "        out_sent = normalizeString(self.df.iloc[idx][self.out_lang.name])\n",
        "\n",
        "        out_list = [\"SOS\"] + out_sent.split(' ')[:self.max_len-2] + [\"EOS\"]\n",
        "        out_list = out_list + [\"PAD\"]*(self.max_len - len(out_list))\n",
        "\n",
        "        out_indexes = [self.out_lang.word2index[word] for word in out_list]\n",
        "\n",
        "        return torch.tensor(inp_indexes, dtype=torch.long), torch.tensor(out_indexes, dtype=torch.long)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "oinIst8cHaS7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31076c84-398c-4193-9e67-413ce114a3f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#Train examples: 320010\n",
            "#Val   examples: 40001\n",
            "#Test  examples: 40002\n"
          ]
        }
      ],
      "source": [
        "df_train = df.sample(frac=0.8, random_state=SEED).reset_index(drop=True)\n",
        "\n",
        "df_test = df.drop(df_train.index).reset_index(drop=True)\n",
        "df_val = df_test.sample(frac=0.5, random_state=SEED).reset_index(drop=True)\n",
        "\n",
        "df_test = df_test.drop(df_val.index).reset_index(drop=True)\n",
        "\n",
        "\n",
        "print(f\"#Train examples: {len(df_train)}\")\n",
        "print(f\"#Val   examples: {len(df_test)}\")\n",
        "print(f\"#Test  examples: {len(df_val)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "d80SFdjDHaS8"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "MAX_LEN = 14\n",
        "BATCH_SIZE = 64 # 128 better\n",
        "\n",
        "input_lang = ita_lang\n",
        "output_lang = eng_lang\n",
        "\n",
        "train_dataset = TranslationDataset(df_train, input_lang, output_lang, MAX_LEN)\n",
        "val_dataset = TranslationDataset(df_val, input_lang, output_lang, MAX_LEN)\n",
        "test_dataset = TranslationDataset(df_test, input_lang, output_lang, MAX_LEN)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qowa3LIDHaS9"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "### **The Encoder-Decoder Architecture**\n",
        "\n",
        "Finally, in this section we will start coding our PyTorch architecture."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RNN Encoder**\n",
        "\n",
        "Reads the source sentence and produces its representation"
      ],
      "metadata": {
        "id": "-rL4s5m1FeqG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "x0lps1fsHaS-"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class EncoderRNN(nn.Module):\n",
        "\n",
        "  def __init__(self, vocab_size, embedding_size, hidden_size, dropout_p=0.1):\n",
        "    super(EncoderRNN, self).__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
        "    self.dropout = nn.Dropout(dropout_p)\n",
        "    self.gru = nn.GRU(embedding_size, hidden_size, batch_first=True)\n",
        "\n",
        "\n",
        "  def forward(self, input_tensor):\n",
        "    # input:  bs, seq_len, 1\n",
        "    # hidden: 1, bs, hs\n",
        "    # output: bs, seq_len, hs\n",
        "\n",
        "    embedded = self.dropout(self.embedding(input_tensor))\n",
        "    outputs, hidden = self.gru(embedded)\n",
        "    return outputs, hidden\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJPj9FkyHaS_"
      },
      "source": [
        "**RNN Decoder**\n",
        "\n",
        "Uses source representation from the encoder to generate the target sentence with the help of Attention module"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BahdanauAttention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "\n",
        "        self.Wa = nn.Linear(hidden_size, hidden_size) #W1\n",
        "        self.Ua = nn.Linear(hidden_size, hidden_size) #W2\n",
        "        self.Va = nn.Linear(hidden_size, 1)\n",
        "\n",
        "\n",
        "    def forward(self, last_decoder_output, encoder_outputs):\n",
        "        a = self.Wa(last_decoder_output)\n",
        "        b = self.Ua(encoder_outputs)\n",
        "        scores = self.Va(torch.tanh(a + b))\n",
        "        scores = scores.squeeze(2).unsqueeze(1)\n",
        "\n",
        "        weights = F.softmax(scores, dim=-1)\n",
        "        context = torch.bmm(weights, encoder_outputs)\n",
        "\n",
        "        return context, weights"
      ],
      "metadata": {
        "id": "RvDp125MFtLg"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "glIYu3m9HaTA"
      },
      "outputs": [],
      "source": [
        "class AttDecoderRNN(nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_size, hidden_size, output_size, dropout_p, max_len, device, sos_token_ind):\n",
        "        super(AttDecoderRNN, self).__init__()\n",
        "\n",
        "        self.max_len = max_len\n",
        "        self.device = device\n",
        "        self.sos_token_ind = sos_token_ind\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, embedding_size)\n",
        "        self.attention = BahdanauAttention(hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size + embedding_size, hidden_size, batch_first=True)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "\n",
        "    def forward_step(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "\n",
        "        # shape: hidden -> (1, batch_size, hidden_size) -- Attention need batch first!\n",
        "        context, attn_weights = self.attention(hidden.permute(1, 0, 2), encoder_outputs)\n",
        "\n",
        "        input_gru = torch.cat((embedded, context), dim=2)\n",
        "\n",
        "        output, hidden = self.gru(input_gru, hidden)\n",
        "        output = F.softmax(self.out(output), dim=-1)\n",
        "\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "\n",
        "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
        "        decoder_input = torch.tensor([[self.sos_token_ind]]*encoder_outputs.size(0),\n",
        "                                     dtype=torch.long,\n",
        "                                     device=self.device)\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoder_outputs = []\n",
        "        attentions = []\n",
        "\n",
        "        for i in range(self.max_len):\n",
        "            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n",
        "                decoder_input, decoder_hidden, encoder_outputs\n",
        "            )\n",
        "            decoder_outputs.append(decoder_output)\n",
        "            attentions.append(attn_weights)\n",
        "\n",
        "            # Teacher forcing: Feed the target as the next input\n",
        "            if target_tensor is not None:\n",
        "                decoder_input = target_tensor[:, i].unsqueeze(1)\n",
        "\n",
        "            # Without teacher forcing: use its own predictions as the next input\n",
        "            else:\n",
        "                _, topi = decoder_output.topk(1)\n",
        "                decoder_input = topi.squeeze(-1).detach()\n",
        "\n",
        "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
        "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
        "        attentions = torch.cat(attentions, dim=1)\n",
        "\n",
        "        return decoder_outputs, decoder_hidden, attentions\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "from tqdm import tqdm\n",
        "from torch.optim import Adam\n",
        "from torch.amp import GradScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "class EncoderDecoder(nn.Module):\n",
        "\n",
        "    def __init__(self, encoder, decoder, model_name, device):\n",
        "        super(EncoderDecoder, self).__init__()\n",
        "\n",
        "        self.model_name = model_name\n",
        "        self.device = device\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "\n",
        "    def forward(self, input_tensor, target_tensor):\n",
        "        encoder_outputs, encoder_hidden = self.encoder(input_tensor)\n",
        "        decoder_outputs, _, _ = self.decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
        "\n",
        "        return decoder_outputs\n",
        "\n",
        "\n",
        "    def train_architecture(self, train_data, val_data, epochs, criterion, optimizer, scaler):\n",
        "\n",
        "        train_losses = []\n",
        "        val_losses = []\n",
        "        accuracies = []\n",
        "        best_valloss = np.inf\n",
        "        best_ep = 0\n",
        "        best_model = copy.deepcopy(self.state_dict())\n",
        "\n",
        "        for ep in tqdm(range(epochs)):\n",
        "            self.train()\n",
        "            ep_loss = 0.0\n",
        "\n",
        "            for batch in train_data:\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                input_tensor, target_tensor = [b.to(self.device) for b in batch]\n",
        "\n",
        "                output_tensor = self(input_tensor, target_tensor)\n",
        "\n",
        "                # Flatten the tensor on the batch_size x seq_len:\n",
        "                # output_tensor: (64, 14, 27230) -> (896, 27230)\n",
        "                # target_tensor: (64, 14) -> (896)\n",
        "                loss = criterion(output_tensor.view(-1, output_tensor.size(-1)), target_tensor.view(-1))\n",
        "\n",
        "                ep_loss += loss.item()\n",
        "\n",
        "                # Backpropagation\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "\n",
        "            train_losses.append(ep_loss/len(train_data))\n",
        "\n",
        "            # Evaluation\n",
        "\n",
        "            val_loss, accuracy = self.eval_model(val_data, criterion)\n",
        "            accuracies.append(accuracy)\n",
        "            val_losses.append(val_loss)\n",
        "\n",
        "            if val_loss < best_valloss:\n",
        "                best_valloss = val_loss\n",
        "                best_model = copy.deepcopy(self.state_dict())\n",
        "                best_ep = ep+1\n",
        "\n",
        "            torch.save(best_model, f\"models/{self.model_name}.pth\")\n",
        "\n",
        "        return train_losses, accuracies, val_losses, best_ep, best_valloss\n",
        "\n",
        "\n",
        "    def eval_model(self, val_data, criterion):\n",
        "        self.eval()\n",
        "\n",
        "        val_loss = 0.0\n",
        "        val_preds = []\n",
        "        val_labels = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in val_data:\n",
        "                input_tensor, target_tensor = [b.to(self.device) for b in batch]\n",
        "\n",
        "                output_tensor = self(input_tensor, target_tensor)\n",
        "                loss = criterion(output_tensor.view(-1, output_tensor.size(-1)), target_tensor.view(-1))\n",
        "\n",
        "                predictions = output_tensor.argmax(dim=-1)\n",
        "\n",
        "                val_loss += loss.item()\n",
        "                val_preds.extend(predictions.cpu().numpy().flatten())\n",
        "                val_labels.extend(target_tensor.cpu().numpy().flatten())\n",
        "\n",
        "        return val_loss/len(val_data), accuracy_score(val_labels, val_preds)\n",
        "\n",
        "\n",
        "    def generate(self, test_data):\n",
        "        self.eval()\n",
        "\n",
        "        test_preds = []\n",
        "        test_labels = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in test_data:\n",
        "                input_tensor, target_tensor = [b.to(self.device) for b in batch]\n",
        "\n",
        "                output_tensor = self(input_tensor, target_tensor)\n",
        "                predictions = output_tensor.argmax(dim=-1)\n",
        "\n",
        "                test_preds.extend(predictions.cpu().numpy().flatten())\n",
        "                test_labels.extend(target_tensor.cpu().numpy().flatten())\n",
        "\n",
        "        return test_preds, test_labels"
      ],
      "metadata": {
        "id": "9vSmIm_GGaIT"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "!mkdir -p models\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Device loaded: {device}\")\n",
        "\n",
        "embedding_size = 128\n",
        "hidden_size = 256\n",
        "drop_rate = 0.1\n",
        "lr = 0.001\n",
        "epochs = 5\n",
        "\n",
        "sos_token = input_lang.word2index[\"SOS\"]\n",
        "pad_token = input_lang.word2index[\"PAD\"]\n",
        "\n",
        "criterion = nn.NLLLoss(ignore_index=pad_token)\n",
        "scaler = GradScaler()"
      ],
      "metadata": {
        "id": "UCLkwNCLF6iB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52ae316d-37ef-4886-b6f5-b44fb3b38416"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device loaded: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ETXTtkJiJFQW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d7e9543-5896-489c-e100-2e35f0807873"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training the model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 3/5 [10:40<07:07, 213.59s/it]"
          ]
        }
      ],
      "source": [
        "att_encoder = EncoderRNN(input_lang.n_words, embedding_size, hidden_size, drop_rate)\n",
        "att_decoder = AttDecoderRNN(embedding_size, hidden_size, output_lang.n_words, drop_rate, MAX_LEN, device, sos_token)\n",
        "\n",
        "att_model = EncoderDecoder(att_encoder, att_decoder, \"attention\", device).to(device)\n",
        "optimizer = Adam(att_model.parameters(), lr=lr)\n",
        "\n",
        "print(\"Training the model...\")\n",
        "att_train_losses, att_accuracies, att_val_losses, best_ep, best_valloss = att_model.train_architecture(train_loader, val_loader, epochs, criterion, optimizer, scaler)\n",
        "\n",
        "print(f\"\\n\\nBest model at epoch {best_ep} with val loss {round(best_valloss, 4)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSa79izCXD8Z"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(att_train_losses, label=\"Train loss\")\n",
        "plt.plot(att_val_losses, label=\"Validation loss\")\n",
        "plt.ylim(0, 5)\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cF6JR_c-m2_Z"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(att_accuracies, label=\"Attention Model\")\n",
        "plt.ylim(0, 1)\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyqRDLd4HaTE"
      },
      "source": [
        "## Testing <br>\n",
        "BLEU (bilingual evaluation understudy) is an algorithm for evaluating the quality of text which has been machine-translated from one natural language to another. Quality is considered to be the correspondence between a machine's output and that of a human: \"the closer a machine translation is to a professional human translation, the better it is\".\n",
        "\n",
        "**BLEU's output is always a number between 0 and 1.** This value indicates how similar the candidate text is to the reference texts, with values closer to 1 representing more similar texts.\n",
        "\n",
        "\n",
        "*Documentation:*\n",
        "\n",
        " - [NLTK Implementation](https://www.nltk.org/_modules/nltk/translate/bleu_score.html)\n",
        " - [ SmoothingFunction](https://aclanthology.org/W14-3346.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RjRXlsdiHaTE"
      },
      "outputs": [],
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "\n",
        "def compute_bleu(labels, preds):\n",
        "    labels = np.reshape(labels, (round(len(test_preds)/MAX_LEN), MAX_LEN)).tolist()\n",
        "    preds = np.reshape(preds, (round(len(test_preds)/MAX_LEN), MAX_LEN)).tolist()\n",
        "\n",
        "    bleus = []\n",
        "    for ref, cand in zip(labels, preds):\n",
        "        bleus.append(sentence_bleu([ref], cand, weights=[0.25, 0.25, 0.25, 0.25], smoothing_function=SmoothingFunction().method7))\n",
        "\n",
        "    return sum(bleus)/len(bleus)\n",
        "\n",
        "\n",
        "att_model.load_state_dict(torch.load(f\"models/{att_model.model_name}.pth\", weights_only=False))\n",
        "test_preds, test_labels = att_model.generate(test_loader)\n",
        "\n",
        "print(f\"Test Accuracy for {att_model.model_name} model: {round(accuracy_score(test_labels, test_preds)*100, 2)}%\")\n",
        "print(f\"Test BLEU Score for {att_model.model_name} model: {round(compute_bleu(test_labels, test_preds), 2)}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}